{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium + BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ChromeDriver path from your environment variable\n",
    "chrome_driver_path = os.getenv('chrome_driver_path')\n",
    "\n",
    "# Setup WebDriver\n",
    "service = Service(chrome_driver_path)  # Use the path from environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokedex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pokedex_url = \"https://pokemondb.net/pokedex/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get(all_pokedex_url)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for cookie pop-up or other elements\")\n",
    "    \n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract from Soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table body containing all Pokémon rows\n",
    "table_body = soup.find('tbody')\n",
    "rows = table_body.find_all('tr')  # Each row corresponds to one Pokémon\n",
    "\n",
    "# List to store the extracted data\n",
    "pokemon_data = []\n",
    "\n",
    "# Iterate through each row\n",
    "for row in rows:\n",
    "    # Extract the columns\n",
    "    cols = row.find_all('td')\n",
    "    \n",
    "    # Extract individual data points\n",
    "    number = cols[0].find('span', class_='infocard-cell-data').text.strip()\n",
    "    image_url = cols[0].find('img')['src']\n",
    "    name = cols[1].find('a', class_='ent-name').text.strip()\n",
    "\n",
    "    # Check for subtitle\n",
    "    subtitle_tag = cols[1].find('small', class_='text-muted')\n",
    "    subtitle = subtitle_tag.text.strip() if subtitle_tag else \"\"  # Extract text if present\n",
    "\n",
    "    types = [t.text for t in cols[2].find_all('a')]  # Multiple types\n",
    "    total = cols[3].text.strip()\n",
    "    hp = cols[4].text.strip()\n",
    "    attack = cols[5].text.strip()\n",
    "    defense = cols[6].text.strip()\n",
    "    sp_atk = cols[7].text.strip()\n",
    "    sp_def = cols[8].text.strip()\n",
    "    speed = cols[9].text.strip()\n",
    "    \n",
    "    # Append the data as a dictionary\n",
    "    pokemon_data.append({\n",
    "        \"#\": number,\n",
    "        \"Image URL\": image_url,\n",
    "        \"Name\": name,\n",
    "        \"Subtitle\": subtitle,\n",
    "        \"Type\": types,\n",
    "        \"Total\": total,\n",
    "        \"HP\": hp,\n",
    "        \"Attack\": attack,\n",
    "        \"Defense\": defense,\n",
    "        \"Sp. Atk\": sp_atk,\n",
    "        \"Sp. Def\": sp_def,\n",
    "        \"Speed\": speed\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas df\n",
    "df = pd.DataFrame(pokemon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relative path to the data folder\n",
    "relative_path = os.path.join(\"data\", \"pokemon_main_stats_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to the relative path\n",
    "df.to_csv(relative_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the move page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_moves_url = \"https://pokemondb.net/move/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get(all_moves_url)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for cookie pop-up or other elements\")\n",
    "    \n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(service=service)\n",
    "# driver.get(all_moves_url)\n",
    "\n",
    "# soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `soup` contains the BeautifulSoup object of the webpage\n",
    "moves = []\n",
    "\n",
    "# Find all rows of the move table\n",
    "rows = soup.find_all(\"tr\")\n",
    "\n",
    "for row in rows:\n",
    "    # Extract move name\n",
    "    move_name = row.find(\"td\", class_=\"cell-name\")\n",
    "    if not move_name:  # Skip rows without a move name\n",
    "        continue\n",
    "    move_name = move_name.get_text(strip=True)\n",
    "    \n",
    "    # Extract type\n",
    "    move_type = row.find(\"td\", class_=\"cell-icon\")\n",
    "    move_type = move_type.a.get_text(strip=True) if move_type else None\n",
    "\n",
    "    # Extract category\n",
    "    category = row.find(\"td\", class_=\"cell-icon text-center\")\n",
    "    category = category.img[\"title\"] if category and category.img else None\n",
    "\n",
    "    # Extract power\n",
    "    power = row.find_all(\"td\", class_=\"cell-num\")[0].get_text(strip=True)\n",
    "    power = None if power == \"—\" else int(power)\n",
    "\n",
    "    # Extract accuracy\n",
    "    accuracy = row.find_all(\"td\", class_=\"cell-num\")[1].get_text(strip=True)\n",
    "    accuracy = None if accuracy == \"—\" else str(accuracy)\n",
    "\n",
    "    # Extract PP\n",
    "    pp = row.find_all(\"td\", class_=\"cell-num\")[2].get_text(strip=True)\n",
    "    pp = int(pp) if pp.isdigit() else None\n",
    "\n",
    "    # Extract effect\n",
    "    effect = row.find(\"td\", class_=\"cell-long-text\")\n",
    "    effect = effect.get_text(strip=True) if effect else None\n",
    "\n",
    "    # Extract probability\n",
    "    probability = row.find_all(\"td\", class_=\"cell-num\")[-1].get_text(strip=True)\n",
    "    probability = None if probability == \"—\" else int(probability)\n",
    "\n",
    "    # Append the extracted data\n",
    "    moves.append({\n",
    "        \"Move Name\": move_name,\n",
    "        \"Type\": move_type,\n",
    "        \"Category\": category,\n",
    "        \"Power\": power,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"PP\": pp,\n",
    "        \"Effect\": effect,\n",
    "        \"Probability (%)\": probability\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a DataFrame for easier handling\n",
    "df_moves = pd.DataFrame(moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relative path to the data folder\n",
    "relative_path = os.path.join(\"data\", \"pokemon_moves_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to the relative path\n",
    "df_moves.to_csv(relative_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moves per Pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the moves page for bulbasaur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulbasaur_moves_url = \"https://pokemondb.net/pokedex/bulbasaur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get(bulbasaur_moves_url)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for cookie pop-up or other elements\")\n",
    "    \n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(bulbasaur_moves_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table containing moves learnt by level up\n",
    "table = soup.find('table', class_='data-table')\n",
    "\n",
    "# Extract moves\n",
    "moves_level_up = [row.find('td', class_='cell-name').get_text(strip=True)\n",
    "         for row in table.find_all('tr')\n",
    "         if row.find('td', class_='cell-name')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Growl',\n",
       " 'Tackle',\n",
       " 'Vine Whip',\n",
       " 'Growth',\n",
       " 'Leech Seed',\n",
       " 'Razor Leaf',\n",
       " 'Poison Powder',\n",
       " 'Sleep Powder',\n",
       " 'Seed Bomb',\n",
       " 'Take Down',\n",
       " 'Sweet Scent',\n",
       " 'Synthesis',\n",
       " 'Worry Seed',\n",
       " 'Power Whip',\n",
       " 'Solar Beam']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_level_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract moves from TM table\n",
    "moves_tm = []\n",
    "for row in soup.select('table.data-table tbody tr'):\n",
    "    move_cell = row.select_one('.cell-name .ent-name')\n",
    "    if move_cell:\n",
    "        moves_tm.append(move_cell.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Growl',\n",
       " 'Tackle',\n",
       " 'Vine Whip',\n",
       " 'Growth',\n",
       " 'Leech Seed',\n",
       " 'Razor Leaf',\n",
       " 'Poison Powder',\n",
       " 'Sleep Powder',\n",
       " 'Seed Bomb',\n",
       " 'Take Down',\n",
       " 'Sweet Scent',\n",
       " 'Synthesis',\n",
       " 'Worry Seed',\n",
       " 'Power Whip',\n",
       " 'Solar Beam',\n",
       " 'Curse',\n",
       " 'Ingrain',\n",
       " 'Petal Dance',\n",
       " 'Toxic',\n",
       " 'Take Down',\n",
       " 'Charm',\n",
       " 'Protect',\n",
       " 'Acid Spray',\n",
       " 'Trailblaze',\n",
       " 'Facade',\n",
       " 'Magical Leaf',\n",
       " 'Venoshock',\n",
       " 'Endure',\n",
       " 'Sunny Day',\n",
       " 'Bullet Seed',\n",
       " 'False Swipe',\n",
       " 'Body Slam',\n",
       " 'Sleep Talk',\n",
       " 'Seed Bomb',\n",
       " 'Grass Knot',\n",
       " 'Rest',\n",
       " 'Swords Dance',\n",
       " 'Substitute',\n",
       " 'Giga Drain',\n",
       " 'Energy Ball',\n",
       " 'Helping Hand',\n",
       " 'Grassy Terrain',\n",
       " 'Grass Pledge',\n",
       " 'Sludge Bomb',\n",
       " 'Leaf Storm',\n",
       " 'Solar Beam',\n",
       " 'Tera Blast',\n",
       " 'Toxic',\n",
       " 'Knock Off',\n",
       " 'Weather Ball',\n",
       " 'Grassy Glide',\n",
       " 'Double-Edge',\n",
       " 'Curse',\n",
       " 'Growl',\n",
       " 'Tackle',\n",
       " 'Vine Whip',\n",
       " 'Growth',\n",
       " 'Leech Seed',\n",
       " 'Razor Leaf',\n",
       " 'Poison Powder',\n",
       " 'Sleep Powder',\n",
       " 'Seed Bomb',\n",
       " 'Take Down',\n",
       " 'Sweet Scent',\n",
       " 'Synthesis',\n",
       " 'Worry Seed',\n",
       " 'Double-Edge',\n",
       " 'Solar Beam',\n",
       " 'Amnesia',\n",
       " 'Charm',\n",
       " 'Curse',\n",
       " 'Grassy Terrain',\n",
       " 'Ingrain',\n",
       " 'Leaf Storm',\n",
       " 'Magical Leaf',\n",
       " 'Nature Power',\n",
       " 'Petal Dance',\n",
       " 'Power Whip',\n",
       " 'Skull Bash',\n",
       " 'Sludge',\n",
       " 'Toxic',\n",
       " 'Bullet Seed',\n",
       " 'Work Up',\n",
       " 'Sunny Day',\n",
       " 'Light Screen',\n",
       " 'Protect',\n",
       " 'Giga Drain',\n",
       " 'Safeguard',\n",
       " 'Solar Beam',\n",
       " 'Double Team',\n",
       " 'Sludge Bomb',\n",
       " 'Facade',\n",
       " 'Rest',\n",
       " 'Attract',\n",
       " 'Energy Ball',\n",
       " 'False Swipe',\n",
       " 'Endure',\n",
       " 'Flash',\n",
       " 'Swords Dance',\n",
       " 'Sleep Talk',\n",
       " 'Grass Knot',\n",
       " 'Swagger',\n",
       " 'Substitute',\n",
       " 'Cut',\n",
       " 'Strength',\n",
       " 'Rock Smash']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the <h2> tag related to moves learned\n",
    "moves_header = soup.find('h2', string=lambda text: text and \"Moves learned\" in text)\n",
    "\n",
    "# Navigate to the correct <ul> tag after the header\n",
    "correct_list = moves_header.find_next('ul', class_='list-nav panel panel-nav')\n",
    "\n",
    "# Extract the first generation\n",
    "first_generation = correct_list.find('a').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first generation is: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"The first generation is: {first_generation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out pulling the first appeared gen for a random pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this strat for another random pokemon\n",
    "intelon_url = \"https://pokemondb.net/pokedex/inteleon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(intelon_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_2 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the <h2> tag related to moves learned\n",
    "moves_header = soup_2.find('h2', string=lambda text: text and \"Moves learned\" in text)\n",
    "\n",
    "# Navigate to the correct <ul> tag after the header\n",
    "correct_list = moves_header.find_next('ul', class_='list-nav panel panel-nav')\n",
    "\n",
    "# Extract the first generation\n",
    "first_generation = correct_list.find('a').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first generation is: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"The first generation is: {first_generation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
